{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the Data, Make Pandas-able\n",
    "The raw data for this project is an ASE Database that holds the results of the water cluster calculations taken from a recent paper by [Rakshit et al.](https://doi.org/10.1063/1.5128378).\n",
    "We need to convert these ASE `Atoms` objects, which list the atomic coordinates and energy, into a form with the graph structure.\n",
    "As in the [`parse-dataset-from-scratch`](./parse-dataset-from-scartch.ipynb) notebook, we run that conversion here but store the result in a MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 09:37:17.468619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from hydronet.db import HydroNetDB, HydroNetRecord\n",
    "from multiprocessing import Pool\n",
    "from ase.db import connect\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_jobs = min(8, os.cpu_count())  # Number of processes to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the ASE database from the ZIP file\n",
    "We are going to uncompress it temporarily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_zip = zipfile.ZipFile(os.path.join('data', 'input', 'ALL_geoms.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 12 µs, total: 22 µs\n",
      "Wall time: 18.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_path = os.path.join('temp.db', 'water_db', 'ALL_geoms_all_sorted.db')\n",
    "if not os.path.isfile(data_path):\n",
    "    path_check = data_zip.extract('water_db/ALL_geoms_all_sorted.db', 'temp.db')\n",
    "    assert path_check == data_path\n",
    "    print(f'Extracted data to {data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database with 4464740 records\n",
      "CPU times: user 872 µs, sys: 17.1 ms, total: 18 ms\n",
      "Wall time: 17.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ase_db = connect(data_path)\n",
    "total = ase_db.count()\n",
    "print(f'Connected to database with {total} records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the whole dataset to disk\n",
    "Pull records from the ASE DB, convert them to the Mongo-compatible format, and write them to disk. \n",
    "\n",
    "We have a few performance optimizations:\n",
    "1. Read data from the ase database in chunks. Prevents reading the 10GB+ database into memory at one time\n",
    "1. Parallelize converting from ase.Atoms to database records. This step requires detecting hydrogen bonds, which can be time-consuming for larger water clusters\n",
    "1. Write records to disk as completed. Insertion order doesn't matter and this lets us keep the main thread as busy as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pull_from_database(ase_db, chunk_size=128, total=None):\n",
    "    \"\"\"Iterate over a large database\n",
    "    \n",
    "    Queries only a small chunk size at a time to prevent loading the \n",
    "    whole database into memory. \n",
    "    \n",
    "    Args:\n",
    "        ase_db (Connection): Connection to an ASE database\n",
    "        chunk_size (int): Number of entries to retrieve per query\n",
    "        total (int): Total number of entries to retrieve\n",
    "    \"\"\"\n",
    "    # Figure out how many iterations we need to make\n",
    "    if total is None:\n",
    "        total = ase_db.count()\n",
    "    \n",
    "    # Generate the dataset\n",
    "    starts = np.arange(0, total, chunk_size, dtype=np.int32)\n",
    "    \n",
    "    # Iterate through the whole database\n",
    "    for start in starts:\n",
    "        for a in ase_db.select(\n",
    "            selection=[('id','>=', str(start)), ('id', '<', str(start+chunk_size))]):\n",
    "            yield a.toatoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coord_hash_1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo = HydroNetDB.from_connection_info()\n",
    "mongo.initialize_index()  # Sets up unique indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4464740/4464740 [1:12:33<00:00, 1025.47it/s]\n"
     ]
    }
   ],
   "source": [
    "with Pool(n_jobs) as pool:\n",
    "    for record in tqdm(pool.imap_unordered(HydroNetRecord.from_atoms, pull_from_database(ase_db), chunksize=1024), total=total):\n",
    "        # Manually performs a database update\n",
    "        key = record.coord_hash  # Gets the key for the record\n",
    "        record.source = 'wdbase'  # Mark that these came from WDBase\n",
    "        mongo.collection.update_one({'coord_hash': key}, {'$set': record.dict()}, upsert=True)  # Updates the appropriate entry (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 4464642 unique clusters\n",
      "CPU times: user 8.81 ms, sys: 8.9 ms, total: 17.7 ms\n",
      "Wall time: 42.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mongo_size = mongo.collection.count_documents({})\n",
    "print(f'Stored {mongo_size} unique clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustrate the features of the database\n",
    "The database lets us retrieve records and effiicently turn them into different formats, and also has a utility function for adding `ase.Atoms` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start off by demonstrating how to find the lowest-energy cluster with 10 atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.3 ms, sys: 489 µs, total: 16.8 ms\n",
      "Wall time: 37.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cursor = mongo.collection.find({'n_waters': 10}).sort('energy').limit(1)  # Defines a query over the database\n",
    "record = next(cursor)  # Returns the next result in the database query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data here stores some key data (e.g., the energy) as standard data types (e.g., energy as a float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-94.6706543"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['energy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also has some useful data, like a random position in the database used for shuffling and the source from the record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wdbase'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['source']  # Where the data came from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 2, 22, 9, 37, 20, 534000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['create_date']  # When it was added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5477363619379504"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['position']  # Its order in the dataset (used to produce data sorted in a random order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larger data, such as coordiantes, are stored in binary form as pickled numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x02cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nnda'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['coords_'][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a utility class, HydroNetRecord, that allows you to quickly transform this data into desirable formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_waters=10 energy=-94.6706543"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = HydroNetRecord.parse_obj(record)\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, you can access the coordinates as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.58198261, -0.66332477,  5.48388386])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.coords[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or generate a graph or dictionary represntation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7fa02c71c0a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.atomic_nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_waters': 10,\n",
       " 'n_atoms': 10,\n",
       " 'n_bonds': 30,\n",
       " 'atom': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'bond': array([0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 0]),\n",
       " 'connectivity': array([[0, 2],\n",
       "        [0, 5],\n",
       "        [0, 7],\n",
       "        [1, 2],\n",
       "        [1, 5],\n",
       "        [1, 8],\n",
       "        [2, 0],\n",
       "        [2, 1],\n",
       "        [2, 9],\n",
       "        [3, 4],\n",
       "        [3, 6],\n",
       "        [3, 8],\n",
       "        [4, 3],\n",
       "        [4, 5],\n",
       "        [4, 7],\n",
       "        [5, 0],\n",
       "        [5, 1],\n",
       "        [5, 4],\n",
       "        [6, 3],\n",
       "        [6, 7],\n",
       "        [6, 9],\n",
       "        [7, 0],\n",
       "        [7, 4],\n",
       "        [7, 6],\n",
       "        [8, 1],\n",
       "        [8, 3],\n",
       "        [8, 9],\n",
       "        [9, 2],\n",
       "        [9, 6],\n",
       "        [9, 8]]),\n",
       " 'energy': -94.6706543}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.coarse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some utility operations that let you automatically return MongoDB documents as these records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 ms, sys: 1.11 ms, total: 14.5 ms\n",
      "Wall time: 41.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[n_waters=8 energy=-73.3260498,\n",
       " n_waters=8 energy=-73.2936554,\n",
       " n_waters=8 energy=-70.9184799,\n",
       " n_waters=8 energy=-70.8874054,\n",
       " n_waters=8 energy=-70.103035]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cursor = mongo.collection.find({'n_waters': 8}).sort('energy').limit(5)\n",
    "records = list(mongo.iterate_as_records(cursor))  # `list()` iterates over all items in cursor\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how it returns structures with different energies. We have a mechanism in our database that ensures only one document per specific cluster (defined by its coordinates), which cuts down on duplicates\n",
    "\n",
    "To demonstrate, let's re-add cluster number one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo.add_cluster(records[0].atoms)  # Returns \"false\" as the record has already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.1 ms, sys: 88 µs, total: 17.2 ms\n",
      "Wall time: 43.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[n_waters=8 energy=-73.3260498,\n",
       " n_waters=8 energy=-73.2936554,\n",
       " n_waters=8 energy=-70.9184799,\n",
       " n_waters=8 energy=-70.8874054,\n",
       " n_waters=8 energy=-70.103035]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cursor = mongo.collection.find({'n_waters': 8}).sort('energy').limit(5)\n",
    "records = list(mongo.iterate_as_records(cursor))  # `list()` iterates over all items in cursor\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the top cluster is not duplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have some functionality around saving the database to TFrecords that are described further in the class docstrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
