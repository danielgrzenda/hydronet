{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the Data, Make Pandas-able\n",
    "The raw data for this project is an ASE Database that holds the results of the water cluster calculations taken from a recent paper by [Rakshit et al.](https://doi.org/10.1063/1.5128378).\n",
    "We need to convert these ASE `Atoms` objects, which list the atomic coordinates and energy, into a form with the graph structure.\n",
    "As in the [`parse-dataset-from-scratch`](./parse-dataset-from-scartch.ipynb) notebook, we run that conversion here but store the result in a MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T02:11:42.870541Z",
     "iopub.status.busy": "2022-03-12T02:11:42.870151Z",
     "iopub.status.idle": "2022-03-12T02:12:35.588231Z",
     "shell.execute_reply": "2022-03-12T02:12:35.587464Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hydronet.db import HydroNetDB, HydroNetRecord\n",
    "from multiprocessing import Pool\n",
    "from pymongo.errors import BulkWriteError\n",
    "from ase.db import connect\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T02:12:35.606425Z",
     "iopub.status.busy": "2022-03-12T02:12:35.606164Z",
     "iopub.status.idle": "2022-03-12T02:12:35.610105Z",
     "shell.execute_reply": "2022-03-12T02:12:35.609539Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_jobs = min(8, os.cpu_count())  # Number of processes to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the ASE database from the ZIP file\n",
    "We are going to uncompress it temporarily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T02:12:35.613230Z",
     "iopub.status.busy": "2022-03-12T02:12:35.612987Z",
     "iopub.status.idle": "2022-03-12T02:12:35.950775Z",
     "shell.execute_reply": "2022-03-12T02:12:35.950094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_zip = zipfile.ZipFile(os.path.join('data', 'input', 'ALL_geoms.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T02:12:35.954351Z",
     "iopub.status.busy": "2022-03-12T02:12:35.954093Z",
     "iopub.status.idle": "2022-03-12T02:12:36.201787Z",
     "shell.execute_reply": "2022-03-12T02:12:36.201239Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 147 µs, sys: 101 µs, total: 248 µs\n",
      "Wall time: 168 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_path = os.path.join('temp.db', 'water_db', 'ALL_geoms_all_sorted.db')\n",
    "if not os.path.isfile(data_path):\n",
    "    path_check = data_zip.extract('water_db/ALL_geoms_all_sorted.db', 'temp.db')\n",
    "    assert path_check == data_path\n",
    "    print(f'Extracted data to {data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T02:12:36.217270Z",
     "iopub.status.busy": "2022-03-12T02:12:36.217015Z",
     "iopub.status.idle": "2022-03-12T02:14:10.939339Z",
     "shell.execute_reply": "2022-03-12T02:14:10.938640Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database with 4464740 records\n",
      "CPU times: user 300 ms, sys: 2.07 s, total: 2.37 s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ase_db = connect(data_path)\n",
    "total = ase_db.count()\n",
    "print(f'Connected to database with {total} records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the whole dataset to disk\n",
    "Pull records from the ASE DB, convert them to the Mongo-compatible format, and write them to disk. \n",
    "\n",
    "We have a few performance optimizations:\n",
    "1. Read data from the ase database in chunks. Prevents reading the 10GB+ database into memory at one time\n",
    "1. Parallelize converting from ase.Atoms to database records. This step requires detecting hydrogen bonds, which can be time-consuming for larger water clusters\n",
    "1. Write records to disk as completed. Insertion order doesn't matter and this lets us keep the main thread as busy as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T02:14:10.942754Z",
     "iopub.status.busy": "2022-03-12T02:14:10.942531Z",
     "iopub.status.idle": "2022-03-12T02:14:10.948730Z",
     "shell.execute_reply": "2022-03-12T02:14:10.948212Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pull_from_database(ase_db, chunk_size=128, total=None):\n",
    "    \"\"\"Iterate over a large database\n",
    "    \n",
    "    Queries only a small chunk size at a time to prevent loading the \n",
    "    whole database into memory. \n",
    "    \n",
    "    Args:\n",
    "        ase_db (Connection): Connection to an ASE database\n",
    "        chunk_size (int): Number of entries to retrieve per query\n",
    "        total (int): Total number of entries to retrieve\n",
    "    \"\"\"\n",
    "    # Figure out how many iterations we need to make\n",
    "    if total is None:\n",
    "        total = ase_db.count()\n",
    "    \n",
    "    # Generate the dataset\n",
    "    starts = np.arange(0, total, chunk_size, dtype=np.int32)\n",
    "    \n",
    "    # Iterate through the whole database\n",
    "    for start in starts:\n",
    "        for a in ase_db.select(\n",
    "            selection=[('id','>=', str(start)), ('id', '<', str(start+chunk_size))]):\n",
    "            yield a.toatoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T02:14:10.951576Z",
     "iopub.status.busy": "2022-03-12T02:14:10.951353Z",
     "iopub.status.idle": "2022-03-12T02:14:11.592707Z",
     "shell.execute_reply": "2022-03-12T02:14:11.592010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coord_hash_1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo = HydroNetDB.from_connection_info(port=27445)\n",
    "mongo.initialize_index()  # Sets up unique indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T02:14:11.596125Z",
     "iopub.status.busy": "2022-03-12T02:14:11.595820Z",
     "iopub.status.idle": "2022-03-12T12:35:51.123473Z",
     "shell.execute_reply": "2022-03-12T12:35:51.122746Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4464740/4464740 [10:21:39<00:00, 119.70it/s]\n"
     ]
    }
   ],
   "source": [
    "chunksize=1024\n",
    "to_insert = []\n",
    "with Pool(n_jobs) as pool:\n",
    "    for record in tqdm(pool.imap_unordered(HydroNetRecord.from_atoms, pull_from_database(ase_db), chunksize=chunksize), total=total):\n",
    "        # Add it to the list of things to upload\n",
    "        record.source = 'wdbase'  # Mark that these came from WDBase\n",
    "        to_insert.append(record.dict())\n",
    "        \n",
    "        # Use a bulk insert of a certain chunk size\n",
    "        if len(to_insert) >= chunksize:\n",
    "            coord_hashes = [x['coord_hash'] for x in to_insert]\n",
    "            mongo.collection.delete_many({'coord_hash': {'$in': coord_hashes}})\n",
    "            try:\n",
    "                mongo.collection.insert_many(to_insert, ordered=False)\n",
    "            except BulkWriteError:\n",
    "                pass\n",
    "            to_insert.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:35:51.200194Z",
     "iopub.status.busy": "2022-03-12T12:35:51.199990Z",
     "iopub.status.idle": "2022-03-12T12:49:02.542173Z",
     "shell.execute_reply": "2022-03-12T12:49:02.541443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 4464542 unique clusters\n",
      "CPU times: user 297 ms, sys: 211 ms, total: 508 ms\n",
      "Wall time: 13min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mongo_size = mongo.collection.count_documents({})\n",
    "print(f'Stored {mongo_size} unique clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustrate the features of the database\n",
    "The database lets us retrieve records and effiicently turn them into different formats, and also has a utility function for adding `ase.Atoms` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start off by demonstrating how to find the lowest-energy cluster with 10 atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:49:02.545367Z",
     "iopub.status.busy": "2022-03-12T12:49:02.545125Z",
     "iopub.status.idle": "2022-03-12T12:52:19.418030Z",
     "shell.execute_reply": "2022-03-12T12:52:19.417368Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74.2 ms, sys: 54.2 ms, total: 128 ms\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cursor = mongo.collection.find({'n_waters': 10}).sort('energy').limit(1)  # Defines a query over the database\n",
    "record = next(cursor)  # Returns the next result in the database query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data here stores some key data (e.g., the energy) as standard data types (e.g., energy as a float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:52:19.421177Z",
     "iopub.status.busy": "2022-03-12T12:52:19.420948Z",
     "iopub.status.idle": "2022-03-12T12:52:19.426663Z",
     "shell.execute_reply": "2022-03-12T12:52:19.425959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-94.6706543"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['energy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also has some useful data, like a random position in the database used for shuffling and the source from the record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:52:19.429480Z",
     "iopub.status.busy": "2022-03-12T12:52:19.429231Z",
     "iopub.status.idle": "2022-03-12T12:52:19.731032Z",
     "shell.execute_reply": "2022-03-12T12:52:19.730346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wdbase'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['source']  # Where the data came from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:52:19.733812Z",
     "iopub.status.busy": "2022-03-12T12:52:19.733587Z",
     "iopub.status.idle": "2022-03-12T12:52:19.998155Z",
     "shell.execute_reply": "2022-03-12T12:52:19.997729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 3, 12, 2, 14, 25, 650000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['create_date']  # When it was added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:52:20.000861Z",
     "iopub.status.busy": "2022-03-12T12:52:20.000681Z",
     "iopub.status.idle": "2022-03-12T12:52:20.264892Z",
     "shell.execute_reply": "2022-03-12T12:52:20.264264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6870445144874042"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['position']  # Its order in the dataset (used to produce data sorted in a random order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larger data, such as coordiantes, are stored in binary form as pickled numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:52:20.270323Z",
     "iopub.status.busy": "2022-03-12T12:52:20.270072Z",
     "iopub.status.idle": "2022-03-12T12:52:20.589629Z",
     "shell.execute_reply": "2022-03-12T12:52:20.589095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x02cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nnda'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['coords_'][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a utility class, HydroNetRecord, that allows you to quickly transform this data into desirable formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:52:20.592392Z",
     "iopub.status.busy": "2022-03-12T12:52:20.592160Z",
     "iopub.status.idle": "2022-03-12T12:52:20.974906Z",
     "shell.execute_reply": "2022-03-12T12:52:20.974397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_waters=10 energy=-94.6706543"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = HydroNetRecord.parse_obj(record)\n",
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, you can access the coordinates as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:52:20.977460Z",
     "iopub.status.busy": "2022-03-12T12:52:20.977238Z",
     "iopub.status.idle": "2022-03-12T12:52:21.293255Z",
     "shell.execute_reply": "2022-03-12T12:52:21.292813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.58198261, -0.66332477,  5.48388386])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.coords[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or generate a graph or dictionary represntation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:52:21.295864Z",
     "iopub.status.busy": "2022-03-12T12:52:21.295693Z",
     "iopub.status.idle": "2022-03-12T12:52:21.590512Z",
     "shell.execute_reply": "2022-03-12T12:52:21.589904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7fea0711a6d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.atomic_nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:52:21.593172Z",
     "iopub.status.busy": "2022-03-12T12:52:21.592951Z",
     "iopub.status.idle": "2022-03-12T12:52:21.914923Z",
     "shell.execute_reply": "2022-03-12T12:52:21.914506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_waters': 10,\n",
       " 'n_atoms': 10,\n",
       " 'n_bonds': 30,\n",
       " 'atom': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'bond': array([0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 0]),\n",
       " 'connectivity': array([[0, 2],\n",
       "        [0, 5],\n",
       "        [0, 7],\n",
       "        [1, 2],\n",
       "        [1, 5],\n",
       "        [1, 8],\n",
       "        [2, 0],\n",
       "        [2, 1],\n",
       "        [2, 9],\n",
       "        [3, 4],\n",
       "        [3, 6],\n",
       "        [3, 8],\n",
       "        [4, 3],\n",
       "        [4, 5],\n",
       "        [4, 7],\n",
       "        [5, 0],\n",
       "        [5, 1],\n",
       "        [5, 4],\n",
       "        [6, 3],\n",
       "        [6, 7],\n",
       "        [6, 9],\n",
       "        [7, 0],\n",
       "        [7, 4],\n",
       "        [7, 6],\n",
       "        [8, 1],\n",
       "        [8, 3],\n",
       "        [8, 9],\n",
       "        [9, 2],\n",
       "        [9, 6],\n",
       "        [9, 8]]),\n",
       " 'energy': -94.6706543}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.coarse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some utility operations that let you automatically return MongoDB documents as these records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:52:21.917390Z",
     "iopub.status.busy": "2022-03-12T12:52:21.917219Z",
     "iopub.status.idle": "2022-03-12T12:55:45.150240Z",
     "shell.execute_reply": "2022-03-12T12:55:45.149758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.1 ms, sys: 47.8 ms, total: 126 ms\n",
      "Wall time: 3min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[n_waters=8 energy=-73.3260498,\n",
       " n_waters=8 energy=-73.2936554,\n",
       " n_waters=8 energy=-70.9184799,\n",
       " n_waters=8 energy=-70.8874054,\n",
       " n_waters=8 energy=-70.103035]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cursor = mongo.collection.find({'n_waters': 8}).sort('energy').limit(5)\n",
    "records = list(mongo.iterate_as_records(cursor))  # `list()` iterates over all items in cursor\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how it returns structures with different energies. We have a mechanism in our database that ensures only one document per specific cluster (defined by its coordinates), which cuts down on duplicates\n",
    "\n",
    "To demonstrate, let's re-add cluster number one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:55:45.153166Z",
     "iopub.status.busy": "2022-03-12T12:55:45.152967Z",
     "iopub.status.idle": "2022-03-12T12:55:46.730157Z",
     "shell.execute_reply": "2022-03-12T12:55:46.729533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo.add_cluster(records[0].atoms)  # Returns \"false\" as the record has already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T12:55:46.733254Z",
     "iopub.status.busy": "2022-03-12T12:55:46.733005Z",
     "iopub.status.idle": "2022-03-12T12:59:09.982554Z",
     "shell.execute_reply": "2022-03-12T12:59:09.981917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 82 ms, sys: 45.9 ms, total: 128 ms\n",
      "Wall time: 3min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[n_waters=8 energy=-73.3260498,\n",
       " n_waters=8 energy=-73.2936554,\n",
       " n_waters=8 energy=-70.9184799,\n",
       " n_waters=8 energy=-70.8874054,\n",
       " n_waters=8 energy=-70.103035]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cursor = mongo.collection.find({'n_waters': 8}).sort('energy').limit(5)\n",
    "records = list(mongo.iterate_as_records(cursor))  # `list()` iterates over all items in cursor\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the top cluster is not duplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have some functionality around saving the database to TFrecords that are described further in the class docstrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydronet",
   "language": "python",
   "name": "hydronet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
